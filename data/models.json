{
    "Ethiopia_Bure_Jimma_2020": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/0yporfjp",
        "test_metrics": {
            "accuracy": 0.9143,
            "f1_score": 0.8592,
            "precision_score": 0.8041,
            "recall_score": 0.9225,
            "roc_auc_score": 0.9636
        },
        "val_metrics": {
            "accuracy": 0.8903,
            "f1_score": 0.8073,
            "precision_score": 0.7351,
            "recall_score": 0.8952,
            "roc_auc_score": 0.9571
        }
    },
    "Ethiopia_Tigray_2020": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/h89pakgn",
        "test_metrics": {
            "accuracy": 0.8304,
            "f1_score": 0.6884,
            "precision_score": 0.6934,
            "recall_score": 0.6835,
            "roc_auc_score": 0.8502
        },
        "val_metrics": {
            "accuracy": 0.8308,
            "f1_score": 0.7179,
            "precision_score": 0.7,
            "recall_score": 0.7368,
            "roc_auc_score": 0.8805
        }
    },
    "Ethiopia_Tigray_2021": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/3ebyb5g6",
        "test_metrics": {
            "accuracy": 0.8242,
            "f1_score": 0.7193,
            "precision_score": 0.6891,
            "recall_score": 0.7523,
            "roc_auc_score": 0.8782
        },
        "val_metrics": {
            "accuracy": 0.8503,
            "f1_score": 0.744,
            "precision_score": 0.7857,
            "recall_score": 0.7064,
            "roc_auc_score": 0.8765
        }
    },
    "Kenya_2019": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/sthnqh6i",
        "test_metrics": {
            "accuracy": 0.9345,
            "f1_score": 0.6667,
            "precision_score": 0.5806,
            "recall_score": 0.7826,
            "roc_auc_score": 0.941
        },
        "val_metrics": {
            "accuracy": 0.9463,
            "f1_score": 0.5556,
            "precision_score": 0.4348,
            "recall_score": 0.7692,
            "roc_auc_score": 0.9625
        }
    },
    "Malawi_2020": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/ded0f7z5",
        "test_metrics": {
            "accuracy": 0.884,
            "f1_score": 0.5954,
            "precision_score": 0.6094,
            "recall_score": 0.5821,
            "roc_auc_score": 0.9179
        },
        "val_metrics": {
            "accuracy": 0.8612,
            "f1_score": 0.4516,
            "precision_score": 0.359,
            "recall_score": 0.6087,
            "roc_auc_score": 0.8784
        }
    },
    "Namibia_North_2020": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/0px6gsf3",
        "test_metrics": {
            "accuracy": 0.955,
            "f1_score": 0.0909,
            "precision_score": 0.0588,
            "recall_score": 0.2,
            "roc_auc_score": 0.8806
        },
        "val_metrics": {
            "accuracy": 0.9412,
            "f1_score": 0.1935,
            "precision_score": 0.125,
            "recall_score": 0.4286,
            "roc_auc_score": 0.8814
        }
    },
    "Rwanda_2019_skip_era5": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/a9kyjwwt",
        "test_metrics": {
            "accuracy": 0.7153,
            "f1_score": 0.5885,
            "precision_score": 0.5855,
            "recall_score": 0.5916,
            "roc_auc_score": 0.7784
        },
        "val_metrics": {
            "accuracy": 0.7288,
            "f1_score": 0.5937,
            "precision_score": 0.5886,
            "recall_score": 0.5988,
            "roc_auc_score": 0.7811
        }
    },
    "Sudan_Al_Gadaref_2019": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/a2kkq4fs",
        "test_metrics": {
            "accuracy": 0.8735,
            "f1_score": 0.8459,
            "precision_score": 0.8194,
            "recall_score": 0.8741,
            "roc_auc_score": 0.9432
        },
        "val_metrics": {
            "accuracy": 0.8544,
            "f1_score": 0.8067,
            "precision_score": 0.7619,
            "recall_score": 0.8571,
            "roc_auc_score": 0.9393
        }
    },
    "Sudan_Al_Gadaref_2020": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/leg0btix",
        "test_metrics": {
            "accuracy": 0.85,
            "f1_score": 0.8571,
            "precision_score": 0.8219,
            "recall_score": 0.8955,
            "roc_auc_score": 0.9205
        },
        "val_metrics": {
            "accuracy": 0.8586,
            "f1_score": 0.867,
            "precision_score": 0.8224,
            "recall_score": 0.9167,
            "roc_auc_score": 0.933
        }
    },
    "Sudan_Blue_Nile_2019": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/u7z0fftu",
        "test_metrics": {
            "accuracy": 0.9411,
            "f1_score": 0.9086,
            "precision_score": 0.9277,
            "recall_score": 0.8902,
            "roc_auc_score": 0.9875
        },
        "val_metrics": {
            "accuracy": 0.9486,
            "f1_score": 0.9257,
            "precision_score": 0.9205,
            "recall_score": 0.931,
            "roc_auc_score": 0.982
        }
    },
    "Sudan_Blue_Nile_2020": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/sqanaaf6",
        "test_metrics": {
            "accuracy": 0.9379,
            "f1_score": 0.888,
            "precision_score": 0.8333,
            "recall_score": 0.9504,
            "roc_auc_score": 0.9796
        },
        "val_metrics": {
            "accuracy": 0.9028,
            "f1_score": 0.8263,
            "precision_score": 0.7329,
            "recall_score": 0.9469,
            "roc_auc_score": 0.9638
        }
    },
    "Tanzania_February_2019": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/3aept9rs",
        "test_metrics": {
            "accuracy": 0.8552,
            "f1_score": 0.7437,
            "precision_score": 0.8152,
            "recall_score": 0.6837,
            "roc_auc_score": 0.9203
        },
        "val_metrics": {
            "accuracy": 0.8513,
            "f1_score": 0.7406,
            "precision_score": 0.8007,
            "recall_score": 0.6889,
            "roc_auc_score": 0.9076
        }
    },
    "Tanzania_September_2019": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/ri13nskv",
        "test_metrics": {
            "accuracy": 0.8581,
            "f1_score": 0.7515,
            "precision_score": 0.8138,
            "recall_score": 0.6981,
            "roc_auc_score": 0.9169
        },
        "val_metrics": {
            "accuracy": 0.8488,
            "f1_score": 0.7311,
            "precision_score": 0.8092,
            "recall_score": 0.6667,
            "roc_auc_score": 0.9112
        }
    },
    "Uganda_2019": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/dlztexn6",
        "test_metrics": {
            "accuracy": 0.8377,
            "f1_score": 0.5067,
            "precision_score": 0.3878,
            "recall_score": 0.7308,
            "roc_auc_score": 0.8863
        },
        "val_metrics": {
            "accuracy": 0.8458,
            "f1_score": 0.5205,
            "precision_score": 0.4419,
            "recall_score": 0.6333,
            "roc_auc_score": 0.8442
        }
    },
    "Zambia_2019": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/c4n9ioqo",
        "test_metrics": {
            "accuracy": 0.9612,
            "f1_score": 0.5405,
            "precision_score": 0.5882,
            "recall_score": 0.5,
            "roc_auc_score": 0.977
        },
        "val_metrics": {
            "accuracy": 0.9598,
            "f1_score": 0.5556,
            "precision_score": 0.4762,
            "recall_score": 0.6667,
            "roc_auc_score": 0.9398
        }
    },
    "Zambia_2019_skip_era5": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/hgvt6wqk",
        "test_metrics": {
            "accuracy": 0.9499,
            "f1_score": 0.2121,
            "precision_score": 0.2593,
            "recall_score": 0.1795,
            "roc_auc_score": 0.9261
        },
        "val_metrics": {
            "accuracy": 0.955,
            "f1_score": 0.2,
            "precision_score": 0.2727,
            "recall_score": 0.1579,
            "roc_auc_score": 0.9221
        }
    },
    "Zambia_2019_v1": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/4k39krn6",
        "test_metrics": {
            "accuracy": 0.9726,
            "f1_score": 0.7,
            "precision_score": 0.7,
            "recall_score": 0.7,
            "roc_auc_score": 0.9703
        },
        "val_metrics": {
            "accuracy": 0.9749,
            "f1_score": 0.7222,
            "precision_score": 0.619,
            "recall_score": 0.8667,
            "roc_auc_score": 0.9662
        }
    },
    "Zambia_2019_v1_era5": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/kddsrmyt",
        "test_metrics": {
            "accuracy": 0.9635,
            "f1_score": 0.6,
            "precision_score": 0.6,
            "recall_score": 0.6,
            "roc_auc_score": 0.9749
        },
        "val_metrics": {
            "accuracy": 0.9749,
            "f1_score": 0.7222,
            "precision_score": 0.619,
            "recall_score": 0.8667,
            "roc_auc_score": 0.973
        }
    },
    "Zambia_2019_v2": {
        "params": "https://wandb.ai/nasa-harvest/crop-mask/runs/gqni0fso",
        "test_metrics": {
            "accuracy": 0.968,
            "f1_score": 0.65,
            "precision_score": 0.65,
            "recall_score": 0.65,
            "roc_auc_score": 0.9349
        },
        "val_metrics": {
            "accuracy": 0.9724,
            "f1_score": 0.6452,
            "precision_score": 0.625,
            "recall_score": 0.6667,
            "roc_auc_score": 0.9363
        }
    }
}
