{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afffe87f",
   "metadata": {},
   "source": [
    "# Run Presto on Darfur Dataset\n",
    "\n",
    "**Author**: Ivan Zvonkov\n",
    "\n",
    "**Last Modified**: Feb 19, 2024\n",
    "\n",
    "**Description**: Runs Presto on Darfur dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01806419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from datasets import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60792ef",
   "metadata": {},
   "source": [
    "## 1. Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2ba03dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c08b58f9f1f4c54a8ca9370c484e408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1v/87y9n_d5143c_6cp072v3b1c0000gn/T/ipykernel_93729/4119029012.py:4: DtypeWarning: Columns (17) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  df = d.load_df(to_np=True, disable_tqdm=True)\n"
     ]
    }
   ],
   "source": [
    "# Takes a minute and a half\n",
    "dfs = []\n",
    "for d in tqdm(datasets):\n",
    "    df = d.load_df(to_np=True, disable_tqdm=True)\n",
    "    df[\"name\"] = d.name\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs)\n",
    "df[\"is_crop\"] = df[\"class_probability\"] > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377299ac",
   "metadata": {},
   "source": [
    "## 2. Setup training and evaluation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cfd9ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.bboxes import bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b4af85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "training      483\n",
       "testing       375\n",
       "validation    338\n",
       "Name: subset, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"name\"] == \"SudanGedarefDarfurAlJazirah2022\"][\"subset\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe11ee0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "training      277\n",
       "testing       239\n",
       "validation    215\n",
       "Name: subset, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fewer points because many failed on GEE\n",
    "df[df[\"name\"] == \"SudanGedarefDarfurAlJazirah2023\"][\"subset\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb8b66f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_test_2022 = (df[\"name\"] == \"SudanGedarefDarfurAlJazirah2022\") & (df[\"subset\"] != \"training\")\n",
    "is_test_2023 = (df[\"name\"] == \"SudanGedarefDarfurAlJazirah2023\") & (df[\"subset\"] != \"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4abb846",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_name = \"Sudan_South\"\n",
    "\n",
    "is_local_lat = (df.lat >= bboxes[bbox_name].min_lat) & (df.lat <= bboxes[bbox_name].max_lat)\n",
    "is_local_lon = (df.lon >= bboxes[bbox_name].min_lon) & (df.lon <= bboxes[bbox_name].max_lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3dfb1adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have to exclude both test sets from either training sets with Presto\n",
    "# because Presto uses lat lons as input, so bias would be introduced\n",
    "df_train_2022 = df[is_local_lat & is_local_lon & ~is_test_2022 & ~is_test_2022]\n",
    "df_train_2023 = df[is_local_lat & is_local_lon & ~is_test_2023 & ~is_test_2023]\n",
    "df_test_2022 = df[is_test_2022]\n",
    "df_test_2023 = df[is_test_2023]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637aed48",
   "metadata": {},
   "source": [
    "## 3. Convert to Presto Tensor Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "38c642d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from openmapflow.bands import BANDS\n",
    "from src.single_file_presto_v2 import Presto, DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9cb9db11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADD_BY = np.zeros(18)\n",
    "ADD_BY[0:2] = [25.0, 25.0]     # Sentinel-1 VV, VH (range from -50 to 1)\n",
    "ADD_BY[13] = -272.15           # ERA5 Celcius\n",
    "\n",
    "DIVIDE_BY = np.ones(18)\n",
    "DIVIDE_BY[0:2] = [25.0, 25.0]   # Sentinel-1 VV, VH (range from -50 to 1)\n",
    "DIVIDE_BY[2:13] = [10000.0] * 11 # Sentinel-2 high band values\n",
    "DIVIDE_BY[13] = 35.0            # ERA5 high celcius value\n",
    "DIVIDE_BY[14] = 0.03            # ERA5 high precipitation value\n",
    "DIVIDE_BY[15] = 2000.0          # SRTM elevation high value\n",
    "DIVIDE_BY[16] = 50.0            # Slope high value\n",
    "\n",
    "def normalize(x):\n",
    "    keep_indices = [idx for idx, val in enumerate(BANDS) if val != \"B9\"] # remove the b9 band\n",
    "    normalized = ((x + ADD_BY) / DIVIDE_BY).astype(np.float32)\n",
    "    return normalized[:, keep_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db7123bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dw_mask = (torch.ones(12) * 9).long()\n",
    "\n",
    "class PrestoDataset(Dataset):\n",
    "    def __init__(self, arg_df, start_month=1):\n",
    "        xs_list = [normalize(x[start_month:start_month+12]) for x in arg_df[\"eo_data\"].to_list()]\n",
    "        self.xs_tensors = [torch.from_numpy(x).to(DEVICE).float() for x in xs_list]\n",
    "\n",
    "        self.latlons = [np.stack([lat, lon], axis=-1) for lat, lon in zip(arg_df[\"eo_lat\"].to_list(), arg_df[\"eo_lon\"].to_list())]\n",
    "        self.latlons_tensors = [torch.from_numpy(latlon).to(DEVICE).float() for latlon in self.latlons]\n",
    "        \n",
    "        self.is_crop_tensors = [torch.tensor(is_crop, dtype=torch.float32) for is_crop in arg_df[\"is_crop\"].astype(int).to_list()]\n",
    "        self.start_month = start_month\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.xs_tensors)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.xs_tensors[idx]\n",
    "        latlons = self.latlons_tensors[idx]\n",
    "        is_crop = self.is_crop_tensors[idx]\n",
    "        return x, latlons, dw_mask, self.start_month, is_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6372a7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_2022 = PrestoDataset(df_train_2022, start_month=2)\n",
    "test_dataset_2022 = PrestoDataset(df_test_2022, start_month=2) \n",
    "train_dataset_2023 = PrestoDataset(df_train_2023, start_month=2)\n",
    "test_dataset_2023 = PrestoDataset(df_test_2023, start_month=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447134ca",
   "metadata": {},
   "source": [
    "## 4. Generate encodings using Presto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d4948bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_decoder = Presto.load_pretrained(\"../../data/presto/default_model_v2.pt\")\n",
    "pretrained_model = encoder_decoder.encoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "626fe56c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7604a1b41c5c4ecd96dfd5b164eceeec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encodings:   0%|          | 0/146 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m             feature_list\u001b[38;5;241m.\u001b[39mappend(encodings)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mconcatenate(feature_list)\n\u001b[0;32m---> 10\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_encodings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m X_test \u001b[38;5;241m=\u001b[39m generate_encodings(test_dataset)\n\u001b[1;32m     12\u001b[0m y_train \u001b[38;5;241m=\u001b[39m train_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_crop\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list() \n",
      "Cell \u001b[0;32mIn[46], line 6\u001b[0m, in \u001b[0;36mgenerate_encodings\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (x, latlons, dw, start_month, _) \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncodings\u001b[39m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 6\u001b[0m         encodings \u001b[38;5;241m=\u001b[39m (\u001b[43mpretrained_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdynamic_world\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatlons\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlatlons\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_month\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m      7\u001b[0m         feature_list\u001b[38;5;241m.\u001b[39mappend(encodings)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mconcatenate(feature_list)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": [
    "def generate_encodings(dataset):\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=64, shuffle=False)\n",
    "    feature_list = []\n",
    "    for (x, latlons, dw, start_month, _) in tqdm(dataloader, desc=\"Encodings\", leave=False):\n",
    "        with torch.no_grad():\n",
    "            encodings = (pretrained_model(x, dynamic_world=dw, latlons=latlons, month=start_month).cpu().numpy())\n",
    "            feature_list.append(encodings)\n",
    "    return np.concatenate(feature_list)\n",
    "\n",
    "X_train = generate_encodings(train_dataset)\n",
    "X_test = generate_encodings(test_dataset)\n",
    "y_train = train_df[\"is_crop\"].to_list() \n",
    "y_test = test_df[\"is_crop\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5170506",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
