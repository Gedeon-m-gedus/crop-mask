{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CEO Labeling Meta-Statistics\n",
    "**Author:** Benjamin Yeh (by253@cornell.edu / byeh1@umd.edu) <br>\n",
    "**Description:** This notebook contains:\n",
    "1. Code to generate dataframe containing meta information from labeler sets \n",
    "2. Code to generate statistics from meta dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Generate Meta Dataframe \n",
    "\n",
    "The steps for generating the meta dataframe are outlined below:\n",
    "* User defines parameters of project:\n",
    "    * 1.1 `completed_date` - Date when all plots are labeled for *both* sets 1 and 2.\n",
    "    * 1.2 `final_date` - Date when all labels *should* be in agreement between sets 1 and 2.\n",
    "    * 1.3 `IS_AREA_CHANGE` - Indicates whether labeling project is area change (multi-year) or cropmap (single-year).\n",
    "    * 1.4 `YEAR` - Indicates year(s) of labeling project observations. \n",
    "* Meta dataframe is generated by the following process:\n",
    "    * 2.1 A dataframe of the labels at the completed date for sets 1 and 2 is made, and disagreeing points are found by comparing the difference between the two sets.\n",
    "    * 2.2 A dataframe of the labels at the final date for sets 1 and 2 is made, and the final labels *at* the disagreeing points found in the above step are extracted.\n",
    "    * 2.3 A dataframe is made from the disagreeing points, their initial labels from set 1 and 2, and the final labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dates\n",
    "completed_date = \"01-10\"\n",
    "final_date = \"01-17\"\n",
    "\n",
    "# Indicate below whether labeling project is area change (multi-year) or cropmap (single-year)\n",
    "IS_AREA_CHANGE = True\n",
    "\n",
    "# If area change project, indicate each year of observations\n",
    "if IS_AREA_CHANGE:\n",
    "    YEAR_1 = \"2020\"\n",
    "    YEAR_2 = \"2021\"\n",
    "# If cropmap project, indicate single year of observations\n",
    "else:\n",
    "    YEAR = \"\"\n",
    "\n",
    "# Helper function for reading path location of label CSVs \n",
    "#   -> This will need to be modified to resemble user's directory\n",
    "path = lambda s, d: f\"data/ceo-Tigray-2020-2021-Change-({s})-sample-data-2022-{d}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for loading individual labeling CSVs\n",
    "def load_dataframes(completed_date : str, final_date : str):\n",
    "    # Load dataframe for set 1 and 2 @ date where labels are both \"completed\"\n",
    "    complete_dataframe_set_1 = pd.read_csv(path(\"set-1\", completed_date))\n",
    "    complete_dataframe_set_2 = pd.read_csv(path(\"set-2\", completed_date))\n",
    "\n",
    "    # Load dataframe for set 1 and 2 @ date where set 1 and 2 *should* be in \"agreement\"\n",
    "    final_dataframe_set_1 = pd.read_csv(path(\"set-1\", final_date))\n",
    "    final_dataframe_set_2 = pd.read_csv(path(\"set-2\", final_date))\n",
    "\n",
    "    return complete_dataframe_set_1, complete_dataframe_set_2, final_dataframe_set_1, final_dataframe_set_2\n",
    "\n",
    "# Function for computing area change \n",
    "def compute_area_change(label_1 : str, label_2 : str) -> str:\n",
    "    switch = {\n",
    "        (\"Planted\", \"Planted\") : \"Stable P\",\n",
    "        (\"Not planted\", \"Not planted\") : \"Stable NP\",\n",
    "        (\"Planted\", \"Not planted\") : \"P loss\",\n",
    "        (\"Not planted\", \"Planted\") : \"P gain\",\n",
    "    }\n",
    "\n",
    "    return switch[label_1, label_2]\n",
    "        \n",
    "# Function for computing disagreements\n",
    "def compute_disagreements(df1 : pd.DataFrame, df2 : pd.DataFrame):\n",
    "    if IS_AREA_CHANGE:\n",
    "        disagreements = (df1[\"area_change\"] != df2[\"area_change\"])\n",
    "    else:\n",
    "        disagreements = (df1[\"crop_noncrop\"] != df2[\"crop_noncrop\"])\n",
    "        \n",
    "    return disagreements\n",
    "\n",
    "# Function for computing confused points\n",
    "#   -> Where, labelers initially agreed @ completed date; however differ in final\n",
    "#      agreement\n",
    "def compute_confusions(completed_agreements : pd.Series, fdf : pd.DataFrame):\n",
    "    raise NotImplementedError\n",
    "\n",
    "# Aux function for creating meta dataframe\n",
    "def create_meta_dataframe_aux(\n",
    "        cdf1 : pd.DataFrame, \n",
    "        cdf2 : pd.DataFrame, \n",
    "        fdf : pd.DataFrame, \n",
    "        disagreements : pd.Series\n",
    "        ):\n",
    "    \n",
    "    # Extract longitude and latitude from final dataframe\n",
    "    #   -> There may be *slight* variation in `lon` and `lat` across the three dataframes;\n",
    "    #      but otherwise plot/sampleid/lon/lat refer to same locations\n",
    "    lon, lat = fdf.loc[disagreements, \"lon\"].values, fdf.loc[disagreements, \"lat\"].values\n",
    "    \n",
    "    # Extract columns to subset and define helper funcs\n",
    "    columns = [\"plotid\", \"sampleid\", \"email\", \"analysis_duration\"] \n",
    "    if IS_AREA_CHANGE:\n",
    "        columns.append(\"area_change\")\n",
    "        # Helper function for renaming columns by set\n",
    "        rename_fn = lambda s : {\n",
    "            \"area_change\" : f\"{s}_label\",\n",
    "            \"email\" : f\"{s}_email\",\n",
    "            \"analysis_duration\" : f\"{s}_analysis_duration\"\n",
    "        }\n",
    "    else:\n",
    "        columns.append(\"crop_noncrop\")\n",
    "        rename_fn = lambda s : {\n",
    "            \"crop_noncrop\" : f\"{s}_label\",\n",
    "            \"email\" : f\"{s}_email\",\n",
    "            \"analysis_duration\" : f\"{s}_analysis_duration\"\n",
    "        }\n",
    "\n",
    "    # Subset and rename by set\n",
    "    cdf1 = cdf1.loc[disagreements, columns].rename(columns = rename_fn(\"set_1\"))\n",
    "    cdf2 = cdf2.loc[disagreements, columns].rename(columns = rename_fn(\"set_2\"))\n",
    "    fdf = fdf.loc[disagreements, columns].rename(columns = rename_fn(\"final\")).drop(columns = ['final_email', 'final_analysis_duration'])\n",
    "\n",
    "    # Assemble dataframe\n",
    "    meta_dataframe = cdf1.merge(\n",
    "        cdf2, left_on = [\"plotid\",\"sampleid\"], right_on = [\"plotid\",\"sampleid\"]\n",
    "        ).merge(\n",
    "        fdf, left_on = [\"plotid\",\"sampleid\"], right_on = [\"plotid\",\"sampleid\"]\n",
    "        )\n",
    "    \n",
    "    # Insert lon and lat\n",
    "    meta_dataframe[\"lon\"], meta_dataframe[\"lat\"] = lon, lat\n",
    "\n",
    "    # Create \"meta-feature\" columns \n",
    "    #   -> (1) Label overridden\n",
    "    #   -> (2) LabelER overridden\n",
    "    #   -> (3) Correct/incorrect analysis duration\n",
    "\n",
    "    # Convert analysis duration to float\n",
    "    meta_dataframe[[\"set_1_analysis_duration\", \"set_2_analysis_duration\"]] = meta_dataframe[[\"set_1_analysis_duration\", \"set_2_analysis_duration\"]].applymap(\n",
    "        lambda string : float(string.split(\" \")[0])\n",
    "        )\n",
    "\n",
    "    # (1) \n",
    "    compute_incorrect_label = lambda l1, l2, f : l2 if l1 == f else l1 if l2 == f else \"Both\"\n",
    "    meta_dataframe[\"overridden_label\"] = meta_dataframe.apply(\n",
    "        lambda df : compute_incorrect_label(df[\"set_1_label\"], df[\"set_2_label\"], df[\"final_label\"]),\n",
    "        axis = 1\n",
    "        )\n",
    "    \n",
    "    # (2)\n",
    "    compute_incorrect_email = lambda e1, e2, l1, l2, f : e2 if l1 == f else e1 if l2 == f else \"Both\" \n",
    "    meta_dataframe[\"overridden_email\"] = meta_dataframe.apply(\n",
    "        lambda df : compute_incorrect_email(df[\"set_1_email\"], df[\"set_2_email\"], df[\"set_1_label\"], df[\"set_2_label\"], df[\"final_label\"]),\n",
    "        axis = 1\n",
    "        )\n",
    "    \n",
    "    # (3)\n",
    "    compute_incorrect_analysis = lambda t1, t2, l1, l2, f: t2 if l1 == f else t1 if l2 == f else 'Both'\n",
    "    compute_correct_analysis = lambda t1, t2, l1, l2, f: t1 if l1 == f else t2 if l2 == f else 'None'\n",
    "    meta_dataframe[\"overridden_analysis\"] = meta_dataframe.apply(\n",
    "        lambda df : compute_incorrect_analysis(df[\"set_1_analysis_duration\"], df[\"set_2_analysis_duration\"], df[\"set_1_label\"], df[\"set_2_label\"], df[\"final_label\"]),\n",
    "        axis = 1\n",
    "    )\n",
    "    meta_dataframe[\"nonoverridden_analysis\"] = meta_dataframe.apply(\n",
    "        lambda df : compute_correct_analysis(df[\"set_1_analysis_duration\"], df[\"set_2_analysis_duration\"], df[\"set_1_label\"], df[\"set_2_label\"], df[\"final_label\"]),\n",
    "        axis = 1\n",
    "    )\n",
    "\n",
    "    # Rearrange columns\n",
    "    rcolumns = [\n",
    "        \"plotid\", \"sampleid\", \"lon\", \"lat\", \"set_1_email\", \"set_2_email\", \"overridden_email\", \n",
    "        \"set_1_analysis_duration\", \"set_2_analysis_duration\", \"overridden_analysis\", \"nonoverridden_analysis\", \n",
    "        \"set_1_label\", \"set_2_label\", \"final_label\", \"overridden_label\"\n",
    "    ]\n",
    "    meta_dataframe = meta_dataframe[rcolumns]\n",
    "\n",
    "    return meta_dataframe\n",
    "\n",
    "# Function for creating meta dataframe\n",
    "def create_meta_dataframe(completed_date : str, final_date : str):\n",
    "\n",
    "    # (1) Load labeling CSVs to dataframes\n",
    "    cdf1, cdf2, fdf1, fdf2 = load_dataframes(completed_date, final_date)\n",
    "\n",
    "    # (2) If labeling project is area change, compute area change\n",
    "    if IS_AREA_CHANGE:\n",
    "        for df in [cdf1, cdf2, fdf1, fdf2]:\n",
    "            df[\"area_change\"] = df.apply(\n",
    "                lambda df : compute_area_change(df[f\"Was this a planted crop in {YEAR_1}?\"], df[f\"Was this a planted crop in {YEAR_2}?\"]),\n",
    "                axis = 1\n",
    "                )\n",
    "    # (2.5) If cropmap, just rename crop column\n",
    "    else:\n",
    "        for df in [cdf1, cdf2, fdf1, fdf2]:\n",
    "            # TODO: Find what the \"native\" column name is for cropmap project\n",
    "            raise NotImplementedError(\"Native column name for cropmap is unknown.\")\n",
    "    \n",
    "    # (3) Compute disagreements for \"completed\" and \"final\" dataframes\n",
    "    cdisagreements = compute_disagreements(cdf1, cdf2)\n",
    "    fdisagreements = compute_disagreements(fdf1, fdf2)\n",
    "    # Disagreements between set 1 and 2 @ completed date\n",
    "    print(f\"Disagreements Between Set 1 and 2 (Completed): {cdisagreements.sum()}\")\n",
    "    # Disagreements between set 1 and 2 @ final date\n",
    "    #   -> Sanity check - should be none!\n",
    "    print(f\"Disagreements Between Set 1 and 2 (Final): {fdisagreements.sum()}\")\n",
    "    assert (fdisagreements.sum() == 0), \"There should be no disagreements by final labeling date between sets 1 and 2.\"\n",
    "\n",
    "    # (4) Create dataframe from *just* disagreement points:\n",
    "    #     -> plotid/sampleid/lon/lat\n",
    "    #     -> List both email of labeler 1, labeler 2, and labeler overridden\n",
    "    #     -> List both set 1, set 2, overridden, and nonoverridden analysis time duration\n",
    "    #     -> List both set 1, set 2, final, and overridden label\n",
    "\n",
    "    meta_dataframe = create_meta_dataframe_aux(cdf1, cdf2, fdf1, cdisagreements)\n",
    "    \n",
    "    return meta_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disagreements Between Set 1 and 2 (Completed): 49\n",
      "Disagreements Between Set 1 and 2 (Final): 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plotid</th>\n",
       "      <th>sampleid</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>set_1_email</th>\n",
       "      <th>set_2_email</th>\n",
       "      <th>overridden_email</th>\n",
       "      <th>set_1_analysis_duration</th>\n",
       "      <th>set_2_analysis_duration</th>\n",
       "      <th>overridden_analysis</th>\n",
       "      <th>nonoverridden_analysis</th>\n",
       "      <th>set_1_label</th>\n",
       "      <th>set_2_label</th>\n",
       "      <th>final_label</th>\n",
       "      <th>overridden_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>163</td>\n",
       "      <td>163</td>\n",
       "      <td>37.120252</td>\n",
       "      <td>13.520786</td>\n",
       "      <td>jwagner@unistra.fr</td>\n",
       "      <td>bbarker1@umd.edu</td>\n",
       "      <td>Both</td>\n",
       "      <td>124.0</td>\n",
       "      <td>105.2</td>\n",
       "      <td>Both</td>\n",
       "      <td>None</td>\n",
       "      <td>Stable P</td>\n",
       "      <td>P gain</td>\n",
       "      <td>Stable NP</td>\n",
       "      <td>Both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>39.154225</td>\n",
       "      <td>14.230454</td>\n",
       "      <td>hkerner@umd.edu</td>\n",
       "      <td>ckuei@terpmail.umd.edu</td>\n",
       "      <td>Both</td>\n",
       "      <td>43.7</td>\n",
       "      <td>949.7</td>\n",
       "      <td>Both</td>\n",
       "      <td>None</td>\n",
       "      <td>P gain</td>\n",
       "      <td>Stable P</td>\n",
       "      <td>Stable NP</td>\n",
       "      <td>Both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>38.953575</td>\n",
       "      <td>14.075160</td>\n",
       "      <td>hkerner@umd.edu</td>\n",
       "      <td>engineer.arnoldmuhairwe@gmail.com</td>\n",
       "      <td>hkerner@umd.edu</td>\n",
       "      <td>172.2</td>\n",
       "      <td>187.8</td>\n",
       "      <td>172.2</td>\n",
       "      <td>187.8</td>\n",
       "      <td>Stable P</td>\n",
       "      <td>Stable NP</td>\n",
       "      <td>Stable NP</td>\n",
       "      <td>Stable P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>299</td>\n",
       "      <td>299</td>\n",
       "      <td>39.335162</td>\n",
       "      <td>13.653124</td>\n",
       "      <td>hkerner@umd.edu</td>\n",
       "      <td>engineer.arnoldmuhairwe@gmail.com</td>\n",
       "      <td>hkerner@umd.edu</td>\n",
       "      <td>108.4</td>\n",
       "      <td>601.7</td>\n",
       "      <td>108.4</td>\n",
       "      <td>601.7</td>\n",
       "      <td>P gain</td>\n",
       "      <td>Stable NP</td>\n",
       "      <td>Stable NP</td>\n",
       "      <td>P gain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>36.725350</td>\n",
       "      <td>13.779008</td>\n",
       "      <td>hkerner@umd.edu</td>\n",
       "      <td>engineer.arnoldmuhairwe@gmail.com</td>\n",
       "      <td>engineer.arnoldmuhairwe@gmail.com</td>\n",
       "      <td>49.6</td>\n",
       "      <td>584.5</td>\n",
       "      <td>584.5</td>\n",
       "      <td>49.6</td>\n",
       "      <td>Stable P</td>\n",
       "      <td>Stable NP</td>\n",
       "      <td>Stable P</td>\n",
       "      <td>Stable NP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   plotid  sampleid        lon        lat         set_1_email  \\\n",
       "0     163       163  37.120252  13.520786  jwagner@unistra.fr   \n",
       "1     252       252  39.154225  14.230454     hkerner@umd.edu   \n",
       "2     296       296  38.953575  14.075160     hkerner@umd.edu   \n",
       "3     299       299  39.335162  13.653124     hkerner@umd.edu   \n",
       "4     300       300  36.725350  13.779008     hkerner@umd.edu   \n",
       "\n",
       "                         set_2_email                   overridden_email  \\\n",
       "0                   bbarker1@umd.edu                               Both   \n",
       "1             ckuei@terpmail.umd.edu                               Both   \n",
       "2  engineer.arnoldmuhairwe@gmail.com                    hkerner@umd.edu   \n",
       "3  engineer.arnoldmuhairwe@gmail.com                    hkerner@umd.edu   \n",
       "4  engineer.arnoldmuhairwe@gmail.com  engineer.arnoldmuhairwe@gmail.com   \n",
       "\n",
       "   set_1_analysis_duration  set_2_analysis_duration overridden_analysis  \\\n",
       "0                    124.0                    105.2                Both   \n",
       "1                     43.7                    949.7                Both   \n",
       "2                    172.2                    187.8               172.2   \n",
       "3                    108.4                    601.7               108.4   \n",
       "4                     49.6                    584.5               584.5   \n",
       "\n",
       "  nonoverridden_analysis set_1_label set_2_label final_label overridden_label  \n",
       "0                   None    Stable P      P gain   Stable NP             Both  \n",
       "1                   None      P gain    Stable P   Stable NP             Both  \n",
       "2                  187.8    Stable P   Stable NP   Stable NP         Stable P  \n",
       "3                  601.7      P gain   Stable NP   Stable NP           P gain  \n",
       "4                   49.6    Stable P   Stable NP    Stable P        Stable NP  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate and load dataframe \n",
    "meta_dataframe = create_meta_dataframe(completed_date, final_date)\n",
    "meta_dataframe.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Meta Analysis\n",
    "**Questions:**\n",
    "* 1 Distribution of overridden points\n",
    "    * 1.1 What is the distribution of incorrect labels?\n",
    "    * 1.2 What is the distribution of mistaken labels?\n",
    "    * 1.3 What is the exact distribution of label-label changes? \n",
    "* 2 Distribution of labelers overridden\n",
    "    * 2.1 What is the frequency of labelers overridden?\n",
    "* 3 Analysis duration \n",
    "    * 3.1 What is the difference in analysis duration for labels overridden?\n",
    "    * 3.2 Which overridden labels have the highest analysis duration? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1.1** What is the distribution of incorrect labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1a) Distribution of overridden labels\n",
    "\n",
    "def label_overrides(df : pd.DataFrame):\n",
    "    # Subset \n",
    "    sdf = df[df[\"overridden_label\"] != \"Both\"]\n",
    "\n",
    "    # Counts of each label overridden\n",
    "    counts = sdf[\"overridden_label\"].value_counts().sort_index()\n",
    "\n",
    "    # Increment with instances of both\n",
    "    #   -> TODO: Add robustness if none; \n",
    "    bdf = df[df[\"overridden_label\"] == \"Both\"]\n",
    "    if bdf.shape[0] != 0:\n",
    "        for label_1, label_2 in zip(bdf[\"set_1_label\"], bdf[\"set_2_label\"]):\n",
    "            counts[label_1] += 1\n",
    "            counts[label_2] += 1\n",
    "\n",
    "    # Print \n",
    "    print(\"{:^25}\\n{}\".format(\"Incorrect Labels\", \"-\"*25))\n",
    "    for label, count in zip(counts.index, counts.values):\n",
    "        print(\"{:^17}: {:>2}\".format(label, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Incorrect Labels     \n",
      "-------------------------\n",
      "     P gain      :  9\n",
      "     P loss      :  5\n",
      "    Stable NP    : 11\n",
      "    Stable P     : 30\n"
     ]
    }
   ],
   "source": [
    "# Read table as: \"Number of times inital {label} incorrect\"\n",
    "label_overrides(meta_dataframe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1.2** What is the distribution of mistaken labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1b) Distribution of mistaken labels\n",
    "\n",
    "def label_mistakes(df : pd.DataFrame):\n",
    "    # Counts of mistaken label\n",
    "    counts = df[\"final_label\"].value_counts().sort_index()\n",
    "    \n",
    "    # Print\n",
    "    print(\"{:^25}\\n{}\".format(\"Mistaken Labels\", \"-\"*25))\n",
    "    for label, count in zip(counts.index, counts.values):\n",
    "        print(\"{:^17}: {:>2}\".format(label, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Mistaken Labels     \n",
      "-------------------------\n",
      "     P gain      :  4\n",
      "     P loss      :  4\n",
      "    Stable NP    : 33\n",
      "    Stable P     :  8\n"
     ]
    }
   ],
   "source": [
    "# Read table as: \"Number of times final {label} mistaken for something else\"\n",
    "label_mistakes(meta_dataframe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1.3** What is the exact distribution of label-label changes? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1b) Distribution of exact label-label changes\n",
    "\n",
    "def label_transitions(df : pd.DataFrame):\n",
    "    # Subset\n",
    "    sdf = df[df[\"overridden_label\"] != \"Both\"]\n",
    "\n",
    "    # Counts of each label-label transition\n",
    "    transitions = pd.Series(list(zip(sdf[\"overridden_label\"], sdf[\"final_label\"]))).value_counts().sort_index()\n",
    "\n",
    "    # Increment transitions with instances from both incidents\n",
    "    #   -> TODO: Add robustness if none; \n",
    "    bdf = df[df[\"overridden_label\"] == \"Both\"]\n",
    "    if bdf.shape[0] != 0:\n",
    "        for set_label in [\"set_1_label\", \"set_2_label\"]:\n",
    "            temp_transitions = pd.Series(list(zip(bdf[set_label], bdf[\"final_label\"]))).value_counts().sort_index()\n",
    "            transitions = transitions.add(temp_transitions, fill_value = 0)\n",
    "        transitions = transitions.astype(int)\n",
    "\n",
    "    # Print \n",
    "    print(\"{:^43}\\n{}\".format(\"Label-Label Transitions\", \"-\"*42))\n",
    "    for (initial, final), count in zip(transitions.index, transitions.values):\n",
    "        print(\"{:^15} -> {:^15} : {:^3}\".format(initial, final, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Label-Label Transitions          \n",
      "------------------------------------------\n",
      "    P gain      ->    Stable NP    :  7 \n",
      "    P gain      ->    Stable P     :  2 \n",
      "    P loss      ->    Stable NP    :  4 \n",
      "    P loss      ->    Stable P     :  1 \n",
      "   Stable NP    ->     P gain      :  4 \n",
      "   Stable NP    ->     P loss      :  2 \n",
      "   Stable NP    ->    Stable P     :  5 \n",
      "   Stable P     ->     P gain      :  3 \n",
      "   Stable P     ->     P loss      :  3 \n",
      "   Stable P     ->    Stable NP    : 24 \n"
     ]
    }
   ],
   "source": [
    "# Read table as: \"Number of times initially labeled as {left label} by one or both sets, and final agreement was {right label}\"\n",
    "label_transitions(meta_dataframe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2.1** What is the frequency of labelers overridden?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2a) Number of times labeler overridden\n",
    "\n",
    "def labeler_overrides(df : pd.DataFrame):\n",
    "    # Counts of each labeler overridden\n",
    "    counts = df[\"overridden_email\"].value_counts().sort_values(ascending = False)\n",
    "\n",
    "    # Print\n",
    "    print(\"{:^43}\\n{}\".format(\"Frequency of Labeler Overridden\", \"-\"*42))\n",
    "    for labeler, count in zip(counts.index, counts.values):\n",
    "        print(\" {:<34} : {:>3}\".format(labeler, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Frequency of Labeler Overridden      \n",
      "------------------------------------------\n",
      " logdaye@gmail.com                  :  19\n",
      " engineer.arnoldmuhairwe@gmail.com  :   9\n",
      " Both                               :   6\n",
      " ckuei@terpmail.umd.edu             :   5\n",
      " hkerner@umd.edu                    :   4\n",
      " jwagner@unistra.fr                 :   3\n",
      " cnakalem@umd.edu                   :   2\n",
      " taryndev@umd.edu                   :   1\n"
     ]
    }
   ],
   "source": [
    "labeler_overrides(meta_dataframe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3.1** What is the difference in analysis duration for labels overridden?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3a) What is the difference in analysis duration for labels overridden?\n",
    "\n",
    "def median_duration(df : pd.DataFrame):\n",
    "    # Subset \n",
    "    sdf = df[df[\"overridden_label\"] != \"Both\"]\n",
    "\n",
    "    # Subset overridden and nonoverridden analysis times\n",
    "    overridden = sdf[\"overridden_analysis\"].astype(np.float64)\n",
    "    nonoverridden = sdf[\"nonoverridden_analysis\"].astype(np.float64)\n",
    "\n",
    "    # Append overridden analysis time with durations from both incidents\n",
    "    #   -> TODO: Add robustness if none; \n",
    "    bdf = df[df[\"overridden_label\"] == \"Both\"]\n",
    "    if bdf.shape[0] != 0:\n",
    "        overridden = pd.concat([\n",
    "            overridden,\n",
    "            pd.Series(bdf[[\"set_1_analysis_duration\", \"set_2_analysis_duration\"]].astype(np.float64).values.flatten())\n",
    "        ])\n",
    "\n",
    "    # Print median duration times\n",
    "    print(\"{:^37}\\n{}\".format(\"Median Analysis Duration\", \"-\"*35))\n",
    "    print(\n",
    "        \"Overridden Points     : {:.2f} secs \\nNon-Overridden Points : {:.2f} secs\"\n",
    "        .format(overridden.median(), nonoverridden.median())\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Median Analysis Duration       \n",
      "-----------------------------------\n",
      "Overridden Points     : 131.30 secs \n",
      "Non-Overridden Points : 159.10 secs\n"
     ]
    }
   ],
   "source": [
    "# Read table as: \"Median time analysis among disagreed points\"\n",
    "median_duration(meta_dataframe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3.2** Which overridden labels have the highest analysis duration?\n",
    "\n",
    "* Overridden points with short analysis time are most likely obvious mistakes; whereas points overridden with logner analysis duration are more likely indicative of an ambigious point\n",
    "\n",
    "* Identifying ambigious points may be important for:\n",
    "    * (1) Downstream analysis involving alternate area change estimation\n",
    "    * (2) Deriving a systematic disagreement resolvment involving difficult points that are *currently* being skipped in model training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highest_duration(df : pd.DataFrame, q : float):\n",
    "    # (2) Combine durations across both sets\n",
    "    durations = df[[\"set_1_analysis_duration\", \"set_2_analysis_duration\"]].values.flatten()\n",
    "    \n",
    "    # (3) Find qth quantile of analysis durations\n",
    "    quantile = np.quantile(durations, q) \n",
    "\n",
    "    # (4) Subset df where analysis durations higher than q \n",
    "    #       -> In either set 1 or set 2\n",
    "    sdf = df[(df[\"set_1_analysis_duration\"] >= quantile) | (df[\"set_2_analysis_duration\"] >= quantile)]\n",
    "    \n",
    "    # (5) Print number of points with analysis duration higher than quantile\n",
    "    print(\"{:^53}\\n{}\".format(\"Highest Analysis Durations\", \"-\"*52))\n",
    "    print(\n",
    "        \"{:.2f} Quantile of Analysis Durations : {:.2f} secs \\nAnalysis Time Greater than {:.2f} Quantile : {} points\"\n",
    "        .format(q, quantile, q, sdf.shape[0])\n",
    "    )\n",
    "    \n",
    "    # (6) Label-label transitions from points with analysis duration higher than quantile\n",
    "    tdf = sdf[sdf[\"overridden_label\"] != \"Both\"]\n",
    "    transitions = pd.Series(list(zip(tdf[\"overridden_label\"], tdf[\"final_label\"]))).value_counts().sort_index()\n",
    "\n",
    "    # (6) Increment transitions count with instances from both incidents\n",
    "    #   -> TODO: Add robustness if none; \n",
    "    bdf = sdf[sdf[\"overridden_label\"] == \"Both\"]\n",
    "    if bdf.shape[0] != 0:\n",
    "        for set_label in [\"set_1_label\", \"set_2_label\"]:\n",
    "            temp_transitions = pd.Series(list(zip(bdf[set_label], bdf[\"final_label\"]))).value_counts().sort_index()\n",
    "            transitions = transitions.add(temp_transitions, fill_value = 0)\n",
    "        transitions = transitions.astype(int)\n",
    "\n",
    "    # Print label-label transitions\n",
    "    print(\"\\n{:^53}\\n{}\".format(\"Label-Label Transitions\", \"-\"*52))\n",
    "    for (initial, final), count in zip(transitions.index, transitions.values):\n",
    "        print(\"{:^25} -> {:^15} : {:^3}\".format(initial, final, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Highest Analysis Durations              \n",
      "----------------------------------------------------\n",
      "0.85 Quantile of Analysis Durations : 592.24 secs \n",
      "Analysis Time Greater than 0.85 Quantile : 15 points\n",
      "\n",
      "               Label-Label Transitions               \n",
      "----------------------------------------------------\n",
      "         P gain           ->    Stable NP    :  4 \n",
      "         P gain           ->    Stable P     :  1 \n",
      "        Stable NP         ->     P gain      :  1 \n",
      "        Stable NP         ->    Stable P     :  2 \n",
      "        Stable P          ->     P gain      :  1 \n",
      "        Stable P          ->     P loss      :  2 \n",
      "        Stable P          ->    Stable NP    :  6 \n"
     ]
    }
   ],
   "source": [
    "# Read table as: \"Among q-th quantile of analysis times for disagreed points\"\n",
    "# Note: transition tabel follows same logic as above, where 'count' denotes occurence of \n",
    "#       {left label} by either one or both sets. hence, total count may exceed no. points!\n",
    "highest_duration(meta_dataframe, 0.85)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a3e2b61d03c78061a671104db916e662e8ffd3497eaf90b98eebd129a2bf840"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
