{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Intercomparison Demo**\n",
    "\n",
    "**Author:** Adam Yang (ayang115@umd.edu) and Hannah Kerner (hkerner@asu.edu)\n",
    "\n",
    "**Description** Demo for Intercomparison Script: extracts manually labeled test points from publicly-available land cover maps (Harvest, Copernicus, ESA, GLAD, etc) and evaluates performance metrics for each map.\n",
    "\n",
    "**Setup** Make sure you authenticate GEE by running the following from your command line:\n",
    "- `gcloud auth login`\n",
    "- `gcloud auth application-default login`\n",
    "- `earthengine authenticate --auth_mode gcloud`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ee\n",
    "from shapely import wkt\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from src.compare_covermaps import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps = [v for v in TARGETS.values()]\n",
    "countries = [\n",
    "             \"Togo\", \"Kenya\", \"Malawi\", \"Tanzania\", \"Mali\", \"Namibia\", \"Rwanda\", \"Uganda\", \"Zambia\",\n",
    "             \"Hawaii\", \"BlueNile2020\", \"BlueNile2019\", \"AlGadaref2019\", \"BureJimma2019\", \"BureJimma2020\",\n",
    "             \"Tigray2021\", \"Tigray2020\", \"Senegal\"\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covermap_test = TestCovermaps(test_countries=countries, covermaps=maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data points\n",
    "test_pts = covermap_test.get_test_points()\n",
    "\n",
    "# Alternatively, read from existing file\n",
    "# test_pts = pd.read_csv(\"../../intercomparison-data/extracted/test/tgo_ken_tza_mlw_test.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "# test_pts[\"geometry\"] = test_pts[\"geometry\"].apply(wkt.loads)\n",
    "# test_pts = gpd.GeoDataFrame(test_pts, crs=\"epsg:4326\")\n",
    "\n",
    "# Print a random sample of the dataframe\n",
    "test_pts.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes about warnings:\n",
    "# Number of sampled points could be more if there are overlapping images in imagecollection\n",
    "# could only be less if there was missing data in the map?\n",
    "extracted = covermap_test.extract_covermaps(test_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ensemble classifications (mode = voting classifier)\n",
    "# comp_maps = ['copernicus', 'worldcover-v100', 'glad', 'asap', 'dynamicworld', 'gfsad-gcep',\n",
    "#              'digital-earth-africa', 'esa-cci-africa', 'globcover-v23', 'esri-lulc', 'nabil-etal-2021']\n",
    "# Ensemble maps that are available globally\n",
    "comp_maps = ['copernicus', 'worldcover-v200', 'glad','dynamicworld', 'gfsad-gcep', 'globcover-v23', 'esri-lulc']\n",
    "\n",
    "for country in countries:\n",
    "    ensemble_subset = extracted[country][comp_maps].mode(axis='columns')\n",
    "    extracted[country]['ensemble-subset'] = ensemble_subset\n",
    "    \n",
    "covermap_test.sampled_maps = extracted\n",
    "covermap_test.covermap_titles = covermap_test.covermap_titles + ['ensemble-subset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = covermap_test.evaluate()\n",
    "results = pd.concat(covermap_test.results)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"../notebooks/intercomparison-results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "b9a057a3c2bc11d9fb1a09bad675557d69c9743adf6ae74a67a8c76be0d35d72"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
